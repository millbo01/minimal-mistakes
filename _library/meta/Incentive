---
layout: single
title: "Incentive"
permalink: /meta/incentive/
toc: true
toc_label: "Terms"
---

## **Incentive (Meta)**

**Tag:** Meta, Motivation, Reward, Punishment, Driver, Payoff shift

**Definition:**

Anything that shifts expected payoff in the currently dominant tier, making certain actions more or less attractive.

**Full Explanation:**

An incentive isn't just "a reward"—it's anything that changes the expected outcome of a decision in ways that matter to the actor's current dominant tier. The same input can be an incentive or not depending on what tier is active.

Money is an incentive when T4 (means) dominates. But if you're in T2 (tribe) mode, reputation might be stronger. If you're in T3 (safety) mode, threat reduction matters more than money. The incentive isn't in the object—it's in the interaction between the object and the actor's current tier weights.

This is why "we tried incentives and they didn't work" is usually a misdiagnosis. You tried the wrong incentive for the dominant tier. Offering money (T4) to someone operating in T2 (reputation/belonging) mode just reveals you don't understand what's driving them.

Three components determine incentive strength:

1. **Magnitude:** How much does it shift payoff?
2. **Probability:** How likely is the outcome?
3. **Dominant tier match:** Does it affect the tier currently steering behavior?

Incentive is the core unit of IPF. Everything else exists to help you identify: what incentives actually exist (not what's stated), which tier do they affect, and how strong are they really?

**Example 1 (Obvious):**

Sales commission structure. For T4-dominant actors, commission is strong incentive—directly affects means optimization. For T5-dominant actors who care about meaningful work, commission is weak incentive—might even backfire by making work feel transactional and meaningless. Same structure, different tier dominance, completely different behavioral response. The "incentive" only works if it matches the dominant tier.

**Example 2 (Subtle):**

Academic citation counts. Stated goal: measure impact (T5). Actual effect: citation count becomes incentive to publish flashy results, controversial claims, work in high-citation fields (T4 optimization—citations as career means). The metric becomes incentive, but for the wrong tier. Researchers optimize citations instead of truth because the structure makes citations affect career (T4) more reliably than truth-seeking affects career (T5 has weak/delayed link to outcomes). The "incentive" worked—it just incentivized the wrong thing because it targeted the wrong tier.

**Common Misdiagnosis:**

"We have good incentives, they're just not using them right." No—your incentives are either: (1) Targeting wrong tier for what's actually dominant, (2) Too weak/delayed/uncertain to shift behavior, or (3) Crowded out by stronger incentives you're not seeing. If behavior didn't change, your incentive either didn't exist or wasn't aligned with dominant tier.

**Related constructs:**

→ [[Dominant tier]], [[Payoff]], [[Expected value]], [[Utility]], [[Reinforcement]], [[Reward]], [[Punishment]], [[Motivation]], [[Perverse incentives]]

**Diagnostic questions:**

- What tier is actually dominant in this context?
- Does the proposed incentive affect that tier?
- How strong/certain/immediate is the payoff shift?
- Are there stronger competing incentives you're missing?

**Intervention principle:**

Before designing incentives, identify dominant tier. Then:

1. **Match tier:** Incentive must affect the tier currently steering behavior
2. **Check strength:** Must be strong enough to shift optimization given competing pressures
3. **Verify perception:** Actors must believe the incentive exists and will land on them

Most "incentive design" fails by skipping step 1—they design for the tier they wish was dominant, not the tier that actually is.
