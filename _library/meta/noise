---
layout: single
title: "Noise"
permalink: /meta/noise/
toc: true
toc_label: "Terms"
---

## **Noise (Meta)**

**Tag:** Meta, Information degradation, Confusion, Learning barrier, Signal loss

**Definition:**

Input that degrades belief accuracy, distracts attention, or obscures signal without carrying useful information about reality.

**Full Explanation:**

Noise is information that looks like signal but doesn't correlate with reality, or that interferes with signal detection. It's not just absence of signal—it's active interference with learning and updating.

Three types:

1. **Random noise:** Meaningless variation that looks like signal (statistical noise, measurement error)
2. **Adversarial noise:** Deliberate misinformation designed to corrupt models
3. **Volume noise:** So much information that real signal gets buried (can't find pattern in chaos)

Noise is particularly dangerous because it often looks like signal. Actor updates based on noise, their model becomes less accurate, behavior becomes more maladaptive. They're "learning" but learning false patterns.

The modern environment is characterized by historically unprecedented noise levels. Every feedback channel is flooded with gamed metrics, manipulated information, conflicting narratives, and sheer volume. This doesn't just make learning harder—it makes it actively destructive. Actors who try to update become *less* accurate than actors who ignore all feedback.

**Example 1 (Obvious):**

Social media. User sees post: "Study shows coffee prevents cancer" (goes viral). Next day sees: "Study shows coffee causes cancer" (also viral). Both might be real studies with tiny sample sizes and contradictory findings due to statistical noise. User updates model based on whichever appeared more credible/aligned with existing beliefs. Neither post is signal about coffee's actual effects—both are noise. But user's model is now more confident and less accurate. The information made them dumber.

**Example 2 (Subtle):**

Hospital dashboard shows 47 different quality metrics. Some correlate with actual patient outcomes (signal), most are gamed proxies that have Goodharted (noise). Administrator trying to improve care can't distinguish which metrics matter. Spends resources optimizing noise metrics (because they're easier to move) while actual outcomes drift. The dashboard looks like comprehensive feedback but is mostly noise with occasional signal buried in it. The volume prevents learning.

**Common Misdiagnosis:**

Treating more information as always better. "If we just collect more data, we'll understand better" fails when signal-to-noise ratio is low—more data just means more noise, making signal harder to find. Also: believing you can "just ignore" noise. Noise actively corrupts models even when you try to disregard it—filtering is cognitively expensive and imperfect.

**Related constructs:**

→ [[Signal]], [[Clarity]], [[Opacity]], [[Information overload]], [[Misinformation]], [[Gaming]], [[Goodharting]], [[Attention]], [[Model]], [[Update friction]]

**Diagnostic questions:**

- How much of incoming information actually correlates with reality?
- Is there so much information that signal gets buried?
- Is noise random or adversarially generated?
- What's the cost of filtering noise? (cognitive load, time, expertise required?)

**Intervention principle:**

Reduce noise before adding signal:

1. **Filter aggressively:** Remove information that doesn't correlate with outcomes
2. **Simplify:** Fewer, higher-quality metrics beat many noisy ones
3. **Protect signal channels:** Prevent gaming/manipulation of core feedback
4. **Build noise-robust systems:** Assume most information is noise, design for resilience

In high-noise environments, learning is often negative-sum—updating makes you wronger. Better to rely on robust heuristics and occasional high-confidence signals than to try processing everything.
