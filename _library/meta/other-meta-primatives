---
layout: single
title: "Other Meta Primatives"
permalink: /meta/other-meta-primatives/
toc: true
---


### **Payoff (Meta)**

Expected net outcome to the subject, not objective truth. What the actor predicts they'll gain/lose, filtered through their model. Two actors facing same objective situation can perceive completely different payoffs.

### **Expected Value (Meta)**

Payoff adjusted for probability, time delay, and enforcement reliability. Theoretical payoff × (likelihood it happens) × (discount for delay) × (confidence consequences will land). This is what actors actually optimize—not nominal payoffs but expected value given uncertainty.

### **Utility (Meta)**

Internal reward signal architecture determining what feels good/bad. Not always conscious—you can be optimizing for utility you're not aware of. Shaped by evolution, development, and learning. Different people have different utility functions, explaining why identical situations produce different satisfaction.

### **Learning (Meta)**

Policy or belief update over repeated reinforcement. Multiple trials of [action → outcome → feedback] shape behavior automatically. Different from single-shot update—learning is the accumulated effect of many prediction errors with consistent direction.

### **Reinforcement (Meta)**

Reward or punishment signal that shapes future behavior by adjusting policy strength. Positive reinforcement (reward follows action) increases probability of repetition. Negative reinforcement (punishment follows action) decreases probability. Effectiveness depends on consistency, timing, and whether feedback actually reaches actor.

### **Punishment learning (Meta)**

Avoidance policy formation via cost signals—actor learns "doing X causes pain, avoid X." Requires clear attribution (cost must trace to action) and consistency (punishment must follow reliably). Often creates concealment instead of correction if punishment can be avoided by hiding rather than changing.

### **Reward learning (Meta)**

Approach policy formation via gain signals—actor learns "doing X produces reward, repeat X." More effective than punishment for lasting behavior change because creates positive motivation rather than fear-based avoidance. Requires reward to actually land on actor performing desired behavior.

### **Salience (Meta)**

What grabs the model's attention and raises priority. Determines which information gets processed versus ignored. Shaped by: novelty, threat, reward prediction, and existing beliefs (confirmation bias = preferentially attend to belief-confirming information). In high-noise environments, salience determines what penetrates awareness—most information gets filtered out as "not worth noticing."
