---
layout: single
title: "Human Distance"
permalink: /meta/human-distance/
toc: true
toc_label: "Terms"
---

## **Human Distance (Meta)**

**Tag:** Meta, Abstraction, Dehumanization, Model degradation, Empathy loss, Scale dysfunction

**Definition:**

Loss of personhood in the model—when other actors are represented as abstractions, categories, or functions rather than as full humans with inner lives.

**Full Explanation:**

Human distance is what happens when you can't hold someone as a complete person in your model. They become a category (homeless person, terrorist, welfare recipient), a function (the guy who fixes the printer), or a statistic (unemployment rate). The more distance, the less their suffering registers, the easier it is to harm them, the more you optimize around them instead of with them.

Human distance isn't moral failure—it's information compression under cognitive load. You can't hold 8 billion people as full humans in your mind. Your brain compresses. The question is: does the compression preserve enough fidelity for the decisions you're making?

Three sources of human distance:

1. **Scale:** Can't know everyone, must compress to categories
2. **Abstraction:** Indirect contact via reports, metrics, media
3. **Dehumanizing narratives:** Active model corruption that strips personhood

Distance has moral weight because our empathy circuits are designed for close-range operation. Mirror neurons fire when you see someone's face, not when you read statistics. The more distance, the less automatic empathy, the cheaper harm becomes in your optimization.

This is why atrocities are easier at scale. Not because people become evil—because human distance makes the victims abstract enough that harming them doesn't trigger normal inhibitions. Trolley problem: one person on the track feels real, five feels like a number.

**Example 1 (Obvious):**

Drone pilot vs. infantry soldier. Soldier sees faces, hears voices, smells fear—human distance is minimal, killing produces severe psychological cost even when "justified." Drone pilot sees heat signatures on screen, presses button from 7,000 miles away—human distance is maximal, killing produces less psychological cost even when civilians die. Same action (ending lives), completely different subjective experience because distance changes how the targets exist in the operator's model.

**Example 2 (Subtle):**

Executive cutting 10,000 jobs via spreadsheet optimization. Each person has family, mortgage, health issues, identity tied to work. But in executive's model they're "headcount," "cost centers," "redundancies." Not because executive is evil—because at that scale you must compress, and compression strips personhood. If executive had to look each person in the eye and tell them personally, the decision might be different (human distance reduced, empathy engaged). The spreadsheet interface is load-bearing for the decision—it maintains enough distance that harm becomes acceptable.

**Common Misdiagnosis:**

Treating dehumanization as individual moral failure when it's often structural—result of scale, abstraction, and cognitive compression under necessity. Can't fix by exhorting people to "see others' humanity"—need to design systems that preserve human-scale contact when decisions affect humans.

**Related constructs:**

→ [[Abstraction]], [[Psychological distance]], [[Dehumanization]], [[Scale]], [[Empathy]], [[Dunbar's limit]], [[Model compression]], [[Harm]]

**Diagnostic questions:**

- How are other actors represented in the decision-maker's model?
- What's the degree of abstraction/distance?
- Would decision change if distance were reduced?
- Is distance necessary (scale) or artificial (interface design)?

**Intervention principle:**

When decisions affect humans, reduce distance where possible:

- Face-to-face contact over reports/metrics
- Stories over statistics
- Names and faces over categories
- Direct feedback from affected parties
- Site visits, shadowing, immersion

Can't eliminate all distance at scale, but can choose which decisions require low distance and design accordingly. High-stakes human-affecting decisions should have minimum viable distance.
